{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bb21e4",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "### Authors: Mahri Kadyrova, Malek Sibai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c834fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb626ea",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b347f6e",
   "metadata": {},
   "source": [
    "## Question 1: How many invalid entries can you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a86c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95 entries, 0 to 94\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 81 non-null     float64\n",
      " 1   Program            93 non-null     object \n",
      " 2   Year_in_program    92 non-null     object \n",
      " 3   Python_experience  91 non-null     object \n",
      " 4   Stats_experience   90 non-null     object \n",
      " 5   Coding_experience  89 non-null     object \n",
      " 6   Excitement_level   89 non-null     object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Excel file\n",
    "excel_filepath = \"BME1510_Lecture1_Data.xlsx\"\n",
    "\n",
    "# Read the Excel file\n",
    "excel_df = pd.read_excel(excel_filepath)\n",
    "\n",
    "# Get the information about the DataFrame columns\n",
    "df_info = excel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6f931b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19039.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>87957.241469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1072.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>676767.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID\n",
       "count      81.000000\n",
       "mean    19039.358025\n",
       "std     87957.241469\n",
       "min         0.000000\n",
       "25%      1013.000000\n",
       "50%      1072.000000\n",
       "75%      2011.000000\n",
       "max    676767.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary statistics of the DataFrame\n",
    "excel_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06f0a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total length of dataframe: 95\n",
      "Dataframe info:\n",
      "None\n",
      "Dataframe description:\n",
      "                  ID\n",
      "count      81.000000\n",
      "mean    19039.358025\n",
      "std     87957.241469\n",
      "min         0.000000\n",
      "25%      1013.000000\n",
      "50%      1072.000000\n",
      "75%      2011.000000\n",
      "max    676767.000000\n",
      "\n",
      "First column is missing 14 values. Unique values in column ID: [1.00100e+03 1.00200e+03 1.00300e+03 1.00400e+03 1.00500e+03 1.00600e+03\n",
      " 1.00700e+03 1.00800e+03 1.00900e+03 1.01000e+03 1.01100e+03 1.01200e+03\n",
      " 1.01300e+03 1.01400e+03 1.01500e+03 1.01600e+03 1.01700e+03         nan\n",
      " 1.02000e+03 1.02100e+03 1.29000e+03 3.73800e+03 3.06200e+03 1.07900e+03\n",
      " 1.03100e+03 1.03300e+03 1.03000e+03 1.09700e+03 1.44400e+03 1.12700e+03\n",
      " 2.01100e+03 1.04400e+03 1.04500e+03 1.13500e+03 1.07200e+03 1.05200e+03\n",
      " 1.01000e+02 4.09600e+03 1.00000e+00 2.02500e+03 2.42400e+03 1.09200e+03\n",
      " 1.77600e+03 1.06000e+03 1.06400e+03 3.40000e+02 0.00000e+00 3.00000e+03\n",
      " 5.60000e+03 1.21200e+03 1.07000e+03 1.05000e+03 1.07600e+03 1.09600e+03\n",
      " 1.07700e+03 1.23400e+03 4.56780e+04 1.07500e+03 9.09000e+02 2.07600e+03\n",
      " 1.06500e+03 2.43200e+03 1.60000e+03 2.32200e+03 1.23000e+02 2.48976e+05\n",
      " 8.24800e+03 1.75000e+03 6.76767e+05 2.22140e+04 8.39250e+04 1.34730e+04\n",
      " 1.08000e+03 1.99900e+03 3.43822e+05 2.56700e+03]\n",
      "\n",
      "Second column is missing 2 values. Unique values in column Program: ['PhD' 'Masters' 'MEng' 'MASc' 'Meng' 'meng' 'MAsc' 'MEng ' 'Phd' 'MASc '\n",
      " 'MSc' ' ' 'MENG' 'Masc' nan 'Master' 'MASc. ']\n",
      "\n",
      "Third column is missing 3 values. Unique values in column Year_in_program: [1000 1 2 3.5 0 4 5 -2 3 0.5 22 12 69 67 'one' nan]\n",
      "\n",
      "Fourth column is missing 4 values. Unique values in column Python_experience: ['yes' 'no' 'Yes' 'y' nan 'some' 'yep' 'yes ' 'YES' 'No' 'yesss' 'Eh'\n",
      " 'NOOOO' 'what' 'minimal']\n",
      "\n",
      "Fifth column is missing 5 values. Unique values in column Stats_experience: ['yes' 'no' nan 'Yes' 'No' 'yess' 'yep' 'somewhat' 'no.' 'meh' 'Eh' 'umm'\n",
      " 'maybe' 'sure']\n",
      "\n",
      "Sixth column is missing 6 values. Unique values in column Coding_experience: ['yes' 'no' nan 'Yes' 'yep' 'yEs' 'some' 'YES' 'somewhat' 'maybe'\n",
      " 'minimal']\n",
      "\n",
      "Seventh column is missing 6 values. Unique values in column Excitement_level: [3 1 2 'ðŸ‘' nan datetime.datetime(2023, 10, 10, 0, 0) 3.76 'âˆž' 5 7 8.7 9.9\n",
      " 10 8 2.99 4.33 11 'yes' 6 9 0.85 2.9 3.5 12 100 88 100000 -600\n",
      " datetime.datetime(2026, 10, 10, 0, 0) 200 67 0.7 0.8 56478398574.83\n",
      " '80% (nervous)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Total length of dataframe: {len(excel_df)}\n",
    "Dataframe info:\n",
    "{df_info}\n",
    "Dataframe description:\n",
    "{excel_df.describe()}\n",
    "\n",
    "First column is missing {excel_df.iloc[:,0].isna().sum()} values. Unique values in column {excel_df.columns[0]}: {excel_df.iloc[:,0].unique()  }\n",
    "\n",
    "Second column is missing {excel_df.iloc[:,1].isna().sum()} values. Unique values in column {excel_df.columns[1]}: {excel_df.iloc[:,1].unique()  }\n",
    "\n",
    "Third column is missing {excel_df.iloc[:,2].isna().sum()} values. Unique values in column {excel_df.columns[2]}: {excel_df.iloc[:,2].unique()  }\n",
    "\n",
    "Fourth column is missing {excel_df.iloc[:,3].isna().sum()} values. Unique values in column {excel_df.columns[3]}: {excel_df.iloc[:,3].unique()  }\n",
    "\n",
    "Fifth column is missing {excel_df.iloc[:,4].isna().sum()} values. Unique values in column {excel_df.columns[4]}: {excel_df.iloc[:,4].unique()  }\n",
    "\n",
    "Sixth column is missing {excel_df.iloc[:,5].isna().sum()} values. Unique values in column {excel_df.columns[5]}: {excel_df.iloc[:,5].unique()  }\n",
    "\n",
    "Seventh column is missing {excel_df.iloc[:,6].isna().sum()} values. Unique values in column {excel_df.columns[6]}: {excel_df.iloc[:,6].unique()  }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150217fb",
   "metadata": {},
   "source": [
    "#### The invalid entries for each column are different:\n",
    "\n",
    "1. Column ID contains invalid entry which is 14 empty cell while valid entries include numerical ID.\n",
    "\n",
    "2. Column Program contains valid entries which are strings and invalid entries are 2 empty entries.\n",
    "\n",
    "3. Column Year_in_program includes 4 invalid entries that are > 7 (given that usually the longest graduate degree takes about 7 years) or 3 empty entries or 1 string entry since valid entries are numerical entries.\n",
    "\n",
    "4. Column Python_experience includes valid string entries that are variants of yes and no. Invalid entries include 5 missing values, 4 invalid entries (some, eh, what, minimal)\n",
    "\n",
    "5. Column Stats_experience inludes valid strings entries that are variants of yes and no. It includes 5 missing values, 7 invalid string entries (somewhat, meh, eh, umm, maybe, sure)\n",
    "\n",
    "6. Column Coding_experience includes 6 missing values and 3 invalid entries (some, somewhat, maybe, minimal) given valid entries are variants of yes and no\n",
    "\n",
    "7. Column Excitement_level includes valid entries which are numerical values 0-10 and invalid entries include 6 missing entries, 1 emoji, 2 strings, 2 datetime objects, and 8 invalid numerical values >10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf7a77",
   "metadata": {},
   "source": [
    "# Question 2: Suggest reasonable ways to deal with the invalid entries.\n",
    "\n",
    "Some reasonable approaches include:\n",
    "\n",
    "- Continuous: interpolate the values\n",
    "- Discrete: label them as NA delete the value or delete the row\n",
    "- String: label as NA, delete the value, or delete the entire row\n",
    "\n",
    "\n",
    "For each column and each invalid entry, here are suggestions and tradeoffs:\n",
    "\n",
    "1. Column ID contains invalid entry which is 14 empty cell while valid entries include numerical ID. Extrapolate the entries since the ID is increasing by 1 and it is continuous. Pro: filling all the entries and not deleting any rows. Cons: we will miss the unique IDs of participants and may not know who is who.\n",
    "\n",
    "2. Column Program contains valid entries which are strings and invalid entries are 2 empty entries. For this, it may be best to either 1. label NA or 2. delete the rows. The pros for labeling includes keeping the row while the con will be that additional category is added and it is not meaningful category in terms of program.\n",
    "\n",
    "3. Column Year_in_program includes 4 invalid entries that are > 7 (given that usually the longest graduate degree takes about 7 years) or 3 empty entries or 1 string entry since valid entries are numerical entries. The reasonable way to deal will be to delete these rows because we do not know anything about these participants and dealing with outliers might be inefficient. We could also label these entries as NA which lets us preserve them.\n",
    "\n",
    "4. Column Python_experience includes valid string entries that are variants of yes and no. Invalid entries include 5 missing values, 4 invalid entries (some, eh, what, minimal). The reasonable way might be to create a dictionary with possible approximation of each invalid entry to yes or no. The pros is that we are keeping the row and entry, the cons is that it might take time.\n",
    "\n",
    "5. Column Stats_experience inludes valid strings entries that are variants of yes and no. It includes 5 missing values, 7 invalid string entries (somewhat, meh, eh, umm, maybe, sure). The reasonable way might be to create a dictionary with possible approximation of each invalid entry to yes or no. The pros is that we are keeping the row and entry, the cons is that it might take time.\n",
    "\n",
    "6. Column Coding_experience includes 6 missing values and 3 invalid entries (some, somewhat, maybe, minimal) given valid entries are variants of yes and no. The reasonable way might be to create a dictionary with possible approximation of each invalid entry to yes or no. The pros is that we are keeping the row and entry, the cons is that it might take time.\n",
    "\n",
    "7. Column Excitement_level includes valid entries which are numerical values 0-10 and invalid entries include 6 missing entries, 1 emoji, 2 strings, 2 datetime objects, and 8 invalid numerical values >10. The way to deal with these invalid entries are as follows: 1. interpret the symbols and emojis on 0-10 scale (takes time, preserves the entry), rewrite the proportions on 0-10 scale (filtering out these entries may take some code to write, preserves the entry), try to rewrite datetime objects on 0-10 scale by using the day of the datetime object. The pros is that we keep these entries and the cons is that all of these take time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5feab",
   "metadata": {},
   "source": [
    "# Question 3: find the proportion of students in master's program have experience in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c602293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Masterâ€™s students with Python experience: 75.38%\n"
     ]
    }
   ],
   "source": [
    "excel_df['Program'] = excel_df['Program'].map(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "program_types = excel_df['Program'].unique()\n",
    "\n",
    "# Identify master students in dataframe\n",
    "master_vars = [i for i in program_types if isinstance(i, str) and  i.startswith('m')]\n",
    "# print(f'Master program types in dataset: {master_vars}')\n",
    "\n",
    "# Identify python experience types in dataframe\n",
    "python_experience_types = excel_df['Python_experience'].unique()\n",
    "# print(f'Python experience types in dataset: {python_experience_types}')\n",
    "python_experience_vars = [i for i in python_experience_types if isinstance(i, str) and  i.startswith('y')]\n",
    "\n",
    "# Filter only master's students\n",
    "masters_df = excel_df[excel_df['Program'].isin(master_vars)]\n",
    "\n",
    "# Among master's students, filter those with Python experience\n",
    "masters_with_python = masters_df[masters_df['Python_experience'].isin(python_experience_vars)]\n",
    "\n",
    "# Correct proportion\n",
    "proportion_python = len(masters_with_python) / len(masters_df)\n",
    "\n",
    "print(f\"Proportion of Masterâ€™s students with Python experience: {proportion_python:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096ddf4",
   "metadata": {},
   "source": [
    "### My approach focused on the following:\n",
    "\n",
    "- Get the lowercase entries of column Program rows which helps with finding master's program students \n",
    "\n",
    "- The logic behind finding master's program is finding string entries in column Program starting with \"m\" (meng, masc) which lets me count all the possible entries even if they were misspelled. \n",
    "\n",
    "- The logic behind finding master's program students that have experience with python is first finding string entries in column Python_experience starting with \"y\" (yes, yep, y, YES, yesss) which lets me count all the possible entries even if they were misspelled.\n",
    "\n",
    "- Finally, calculate the proportion by dividing the number of Masterâ€™s students with Python experience by the total number of Masterâ€™s students, not the full dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376dea9",
   "metadata": {},
   "source": [
    "# Question 4: find the proportion of students that are excited to be in the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907e21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of students excited for the course: 19.18%\n"
     ]
    }
   ],
   "source": [
    "# Convert the excitement level column to numeric, coercing errors to NaN\n",
    "excel_df['Excitement_level'] = pd.to_numeric(excel_df['Excitement_level'], errors='coerce')\n",
    "\n",
    "# Keep only valid numeric excitement levels (e.g., between 0 and 10)\n",
    "valid_exc_df = excel_df[(excel_df['Excitement_level'] >= 0) & (excel_df['Excitement_level'] <= 10)]\n",
    "\n",
    "# Students excited for the course (excitement level 7 or higher)\n",
    "excited_students = valid_exc_df[valid_exc_df['Excitement_level'] >= 7]\n",
    "\n",
    "# Proportion\n",
    "proportion_excited = len(excited_students) / len(valid_exc_df)\n",
    "\n",
    "print(f\"Proportion of students excited for the course: {proportion_excited:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7182dcb",
   "metadata": {},
   "source": [
    "### My approach focused on the following:\n",
    "\n",
    "- Convert the excitementl level column to numeric values and forcing missing values, string, emojis, etc to become NaN\n",
    "\n",
    "- Then, I filter out the propoer excitement level range of 0-10 while filtering the NaNs, outliers, etc.\n",
    "\n",
    "- Then, I get the dataframe subsection where excitement level is >=7 showing excited student entries\n",
    "\n",
    "- Final step is calculating proportion of entries with values > 7 and divide by total dataframe length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7c712",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5994a1f",
   "metadata": {},
   "source": [
    "## Students in BME1510 are expected to complete six assignments. However, 20% of students miss at least one assignment. Suggest an approach to deal with missing assignment marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dcace0",
   "metadata": {},
   "source": [
    "These are my suggestions:\n",
    "\n",
    "1. You could drop the lowest score in the whole class if your intention is to preserve the relative grade proportions\n",
    "\n",
    "2. You could let the student redo the assignment with the condition that they will have to teach the whole class how they did it, the libraries used, the functions used, what results mean, etc. Maybe set a specific time like presenting for 7 minutes.\n",
    "\n",
    "3. You could design another assignment as an extra credit and all students will have equal opportunity.\n",
    "\n",
    "4. Have the student who did not complete the assignment evaluate another student's or group's submission and suggest improvements on their code.\n",
    "\n",
    "5. Suggest a small topic to present on such as git version control, compare anaconda vs ux for environment control, etc. This will need to be a small project though so that it is fair for that student to not overwork."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bme1510-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
